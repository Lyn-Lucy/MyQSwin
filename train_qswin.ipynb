{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-30T06:55:54.270653Z","iopub.status.busy":"2023-11-30T06:55:54.269798Z","iopub.status.idle":"2023-11-30T06:55:56.193669Z","shell.execute_reply":"2023-11-30T06:55:56.192607Z","shell.execute_reply.started":"2023-11-30T06:55:54.270609Z"},"trusted":true},"outputs":[],"source":["%cd /kaggle/input/tran-qswin-distill\n","!pip uninstall timm --yes\n","import math\n","import sys\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n","from torch.utils.data import Subset\n","\n","from main import * \n","import argparse\n","import quant_swin_transformer\n","# from losses import DistillationLoss\n","from engine import evaluate\n","import swin_transformer\n","\n","import timm\n","from timm.models import create_model\n","from timm.optim import create_optimizer\n","from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy\n","from timm.scheduler import create_scheduler\n","from timm.utils import NativeScaler, get_state_dict, ModelEma, accuracy\n","from timm.data import Mixup\n","import utils\n","from typing import Iterable, Optional\n","\n","\n","parser = argparse.ArgumentParser(parents=[get_args_parser()])\n","args=parser.parse_args(args=[])\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["### datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:55:56.196084Z","iopub.status.busy":"2023-11-30T06:55:56.195726Z","iopub.status.idle":"2023-11-30T06:56:04.898115Z","shell.execute_reply":"2023-11-30T06:56:04.897072Z","shell.execute_reply.started":"2023-11-30T06:55:56.196051Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","#     transforms.RandomCrop(32),\n","#     transforms.RandomHorizontalFlip(),\n","    transforms.Resize(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5071, 0.4865, 0.4409], std=[0.2673, 0.2564, 0.2762])\n","])\n","\n","dataset_train = datasets.CIFAR100(root='/kaggle/working/data', train=True, download=True, transform=transform)\n","dataset_val = datasets.CIFAR100(root='/kaggle/working/data', train=False, download=True, transform=transform)\n","\n","args.batch_size = 32\n","\n","sampler_train = RandomSampler(dataset_train)\n","sampler_val = SequentialSampler(dataset_val)\n","args.pin_mem = False\n","data_loader_train = DataLoader(\n","    dataset_train, sampler=sampler_train,\n","    batch_size=args.batch_size,\n","    num_workers=args.num_workers,\n","    pin_memory=args.pin_mem,\n","    drop_last=True,\n",")\n","\n","data_loader_val = DataLoader(\n","    dataset_val, sampler=sampler_val,\n","    batch_size=int(1.5 * args.batch_size),\n","    num_workers=args.num_workers,\n","    pin_memory=args.pin_mem,\n","    drop_last=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### load teacher_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:56:04.899441Z","iopub.status.busy":"2023-11-30T06:56:04.899178Z","iopub.status.idle":"2023-11-30T06:56:09.211566Z","shell.execute_reply":"2023-11-30T06:56:09.210592Z","shell.execute_reply.started":"2023-11-30T06:56:04.899419Z"},"trusted":true},"outputs":[],"source":["# all_pretrained_models_available = timm.list_models(pretrained=True)\n","# print(all_pretrained_models_available)\n","teacher_model_name = \"swin_tiny_patch4_window7_224\"\n","# teacher_model = None\n","teacher_model = create_model(\n","    teacher_model_name,\n","    pretrained=True,\n","    num_classes=100,\n",")\n","# teacher_model = swin_transformer.SwinTransformer(num_classes=100,patch_size=4, window_size=7, embed_dim=24, depths=(2, 2, 6, 2), num_heads=(3, 3, 3, 3))\n","# teacher_model = swin_transformer.SwinTransformer(num_classes=100)\n","\n","teacher_model.to(device)\n","teacher_model.eval()\n","\n","teacher_model_params = sum(p.numel() for p in teacher_model.parameters())\n","print(f\"Total number of parameters in teacher_model: {teacher_model_params}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:56:09.214632Z","iopub.status.busy":"2023-11-30T06:56:09.213954Z","iopub.status.idle":"2023-11-30T06:56:09.224924Z","shell.execute_reply":"2023-11-30T06:56:09.223778Z","shell.execute_reply.started":"2023-11-30T06:56:09.214595Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.nn import functional as F\n","\n","\n","class DistillationLoss(torch.nn.Module):\n","    \"\"\"\n","    This module wraps a standard criterion and adds an extra knowledge distillation loss by\n","    taking a teacher model prediction and using it as additional supervision.\n","    \"\"\"\n","    def __init__(self, base_criterion: torch.nn.Module, s_t_criterion: torch.nn.Module,teacher_model: torch.nn.Module,\n","                 distillation_type: str, alpha: float, tau: float):\n","        super().__init__()\n","        self.base_criterion = base_criterion\n","        self.s_t_criterion = s_t_criterion\n","        self.teacher_model = teacher_model\n","        assert distillation_type in ['none', 'soft', 'hard']\n","        self.distillation_type = distillation_type\n","        self.alpha = alpha\n","        self.tau = tau\n","\n","    def forward(self, inputs, outputs, labels, model_feature):\n","        \"\"\"\n","        Args:\n","            inputs: The original inputs that are feed to the teacher model\n","            outputs: the outputs of the model to be trained. It is expected to be\n","                either a Tensor, or a Tuple[Tensor, Tensor], with the original output\n","                in the first position and the distillation predictions as the second output\n","            labels: the labels for the base criterion\n","        \"\"\"\n","        teacher_feature = None\n","        def hook_fn_2(module, input, output):\n","            nonlocal teacher_feature\n","            teacher_feature = output[1]\n","        self.teacher_model.layers[-1].blocks[1].attn.register_forward_hook(hook_fn_2)\n","\n","        base_loss = self.base_criterion(outputs, labels)\n","\n","        with torch.no_grad():\n","            teacher_outputs = self.teacher_model(inputs)\n","        s_t_loss = self.s_t_criterion(model_feature,teacher_feature)\n","        \n","        loss = base_loss * (1 - self.alpha) + s_t_loss * self.alpha\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:56:09.226422Z","iopub.status.busy":"2023-11-30T06:56:09.226151Z","iopub.status.idle":"2023-11-30T06:56:09.809086Z","shell.execute_reply":"2023-11-30T06:56:09.807991Z","shell.execute_reply.started":"2023-11-30T06:56:09.226398Z"},"trusted":true},"outputs":[],"source":["# model = quant_swin_transformer.SwinTransformer(num_classes=100,patch_size=4, window_size=7, embed_dim=24, depths=(2, 2, 6, 2), num_heads=(3, 3, 3, 3))\n","model = quant_swin_transformer.SwinTransformer(num_classes=100)\n","\n","# model = create_model(\n","#     teacher_model_name,\n","#     pretrained=True,\n","#     num_classes=100,\n","# )\n","\n","model.to(device)\n","n_parameters = sum(p.numel() for p in model.parameters())\n","print(f\"Total number of parameters in model: {n_parameters}\")\n","\n","\n","optimizer = create_optimizer(args, model)\n","criterion = LabelSmoothingCrossEntropy(smoothing=args.smoothing)\n","s_t_criterion = F.mse_loss\n","criterion = DistillationLoss(\n","    criterion, s_t_criterion, teacher_model, args.distillation_type, args.distillation_alpha, args.distillation_tau\n",")\n","linear_scaled_lr = args.lr * args.batch_size * utils.get_world_size() / 512.0\n","args.lr = linear_scaled_lr\n","loss_scaler = NativeScaler()\n","lr_scheduler, _ = create_scheduler(args, optimizer)\n","output_dir = Path(args.output_dir)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:56:09.811053Z","iopub.status.busy":"2023-11-30T06:56:09.810387Z","iopub.status.idle":"2023-11-30T06:56:09.823281Z","shell.execute_reply":"2023-11-30T06:56:09.822278Z","shell.execute_reply.started":"2023-11-30T06:56:09.810999Z"},"trusted":true},"outputs":[],"source":["def train_one_epoch(model: torch.nn.Module, teacher_model: torch.nn.Module, criterion: DistillationLoss,\n","                    data_loader: Iterable, optimizer: torch.optim.Optimizer,\n","                    device: torch.device, epoch: int, loss_scaler, max_norm: float = 0,\n","                    model_ema: Optional[ModelEma] = None, mixup_fn: Optional[Mixup] = None,\n","                    set_training_mode=True,print_freq = 10):\n","    model.train(set_training_mode)\n","    teacher_model.eval()\n","    student_feature = None\n","\n","    def hook_fn_1(module, input, output):\n","        # 使用 nonlocal 关键字引用外部变量\n","        nonlocal student_feature\n","        # 获取最后一层的特征\n","        student_feature = output[1]\n","    model.layers[-1].blocks[1].attn.register_forward_hook(hook_fn_1)\n","    \n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    header = 'Epoch: [{}]'.format(epoch)\n","\n","    for samples, targets in metric_logger.log_every(data_loader, print_freq, header):\n","        samples = samples.to(device, non_blocking=True)\n","        targets = targets.to(device, non_blocking=True)\n","\n","        outputs = model(samples)\n","        loss = criterion(samples, outputs, targets,student_feature)\n","        loss_value = loss.item()\n","        if not math.isfinite(loss_value):\n","            print(\"Loss is {}, stopping training\".format(loss_value))\n","            sys.exit(1)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        torch.cuda.synchronize()\n","        # if model_ema is not None:\n","        #     model_ema.update(model)\n","\n","        metric_logger.update(loss=loss_value)\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","    # gather the stats from all processes\n","    metric_logger.synchronize_between_processes()\n","    print(\"Averaged stats:\", metric_logger)\n","    return {k: meter.global_avg for k, meter in metric_logger.meters.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-30T06:56:09.824766Z","iopub.status.busy":"2023-11-30T06:56:09.824489Z","iopub.status.idle":"2023-11-30T07:14:48.610874Z","shell.execute_reply":"2023-11-30T07:14:48.609414Z","shell.execute_reply.started":"2023-11-30T06:56:09.824743Z"},"trusted":true},"outputs":[],"source":["max_accuracy = 0.0\n","for epoch in range(args.start_epoch, args.epochs):\n","\n","    train_stats = train_one_epoch(\n","        model, teacher_model, criterion, data_loader_train,\n","        optimizer, device, epoch, loss_scaler,\n","        args.clip_grad, None, None,\n","        set_training_mode=args.finetune == '',  # keep in eval mode during finetuning\n","        print_freq = 100\n","    )\n","\n","    lr_scheduler.step(epoch)\n","    if args.output_dir:\n","        checkpoint_paths = [output_dir / 'checkpoint.pth']\n","        for checkpoint_path in checkpoint_paths:\n","            utils.save_on_master({\n","                'model': model.state_dict(),\n","                'optimizer': optimizer.state_dict(),\n","                'lr_scheduler': lr_scheduler.state_dict(),\n","                'epoch': epoch,\n","                # 'model_ema': get_state_dict(model_ema),\n","                'scaler': loss_scaler.state_dict(),\n","                'args': args,\n","            }, checkpoint_path)\n","\n","\n","    test_stats = evaluate(data_loader_val, model, device)\n","    print(f\"Accuracy of the network on the {len(dataset_val)} test images: {test_stats['acc1']:.1f}%\")\n","\n","    if max_accuracy < test_stats[\"acc1\"]:\n","        max_accuracy = test_stats[\"acc1\"]\n","        if args.output_dir:\n","            checkpoint_paths = [output_dir / 'best_checkpoint.pth']\n","            for checkpoint_path in checkpoint_paths:\n","                utils.save_on_master({\n","                    'model': model.state_dict(),\n","                    'optimizer': optimizer.state_dict(),\n","                    'lr_scheduler': lr_scheduler.state_dict(),\n","                    'epoch': epoch,\n","                    # 'model_ema': get_state_dict(model_ema),\n","                    'scaler': loss_scaler.state_dict(),\n","                    'args': args,\n","                }, checkpoint_path)\n","\n","    print(f'Max accuracy: {max_accuracy:.2f}%')\n","\n","    log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n","                 **{f'test_{k}': v for k, v in test_stats.items()},\n","                 'epoch': epoch,\n","                 'n_parameters': n_parameters}\n","\n","\n","\n","\n","    if args.output_dir and utils.is_main_process():\n","        with (output_dir / \"log.txt\").open(\"a\") as f:\n","            f.write(json.dumps(log_stats) + \"\\n\")\n","\n","total_time = time.time() - start_time\n","total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","print('Training time {}'.format(total_time_str))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4077750,"sourceId":7079044,"sourceType":"datasetVersion"},{"datasetId":4084059,"sourceId":7088051,"sourceType":"datasetVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
